{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPLKO Moduł 7 - praca domowa - HPO\n",
    "\n",
    "To siódma praca domowa w Programie szkoleniowym Klasyfikacja obrazu od Deep Drive PL\n",
    "\n",
    "Twoim zadaniem w tym module będzie jendo z 2:\n",
    "\n",
    "Opcja 1:\n",
    "- [ ] Na bazie pracy domowej z Transfer learningiem, data augmentation\n",
    "- [ ] Wykorzystaj HPO (np. Optunę, Hyperopta bądź KerasTuner) by dobrać parametry treningu (optymalizator, LR), data augmentation (zakresy wartości)\n",
    "- [ ] Udostępnij wykres na Discordzie `#klasyfikacja-wyniki` (val acc - porównanie model przed i po HPO)\n",
    "\n",
    "Opcja 2 (mniejsza moc obliczeniowa):\n",
    "- [ ] Na bazie pracy domowej ze zbiorem **QuickDraw**\n",
    "- [ ] Wykorzystaj HPO (np. Optunę, Hyperopta bądź KerasTuner) by dobrać parametry treningu (optymalizator, LR), i architektury sieci (liczba warstw, dropout, pooling)\n",
    "- [ ] Pracuj na podzbiorze max 100k przykładów\n",
    "- [ ] Udostępnij wykres na Discordzie `#klasyfikacja-wyniki` (val acc - porównanie model przed i po HPO)\n",
    "\n",
    "Możesz extra (czyli opcjonalne rzeczy):\n",
    "- Spróbować użyć AutoKeras by znaleźć architekturę dla problemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.integration import TFKerasPruningCallback, TensorBoardCallback\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid',font_scale=1.5)\n",
    "\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 22050\n",
      "Val: 9450\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_val),info = tfds.load(\n",
    "    \"resisc45\",\n",
    "    split=[\"train[:70%]\", \"train[70%:100%]\"],\n",
    "    as_supervised=True,  # Include labels\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "print('Train:',len(ds_train))\n",
    "print('Val:',len(ds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size=32\n",
    "\n",
    "size = (img_size, img_size)\n",
    "\n",
    "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_train = ds_train.batch(batch_size=batch_size, drop_remainder=True)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_val = ds_val.map(lambda image, label: (tf.image.resize(image, size), label))\n",
    "ds_val = ds_val.batch(batch_size=batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = info.features['label'].names\n",
    "\n",
    "num_classes = len(class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 8)       224       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 128, 128, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 45)                11565     \n",
      "=================================================================\n",
      "Total params: 405,117\n",
      "Trainable params: 405,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def getModel(lr, pooling, flatten, convs):\n",
    "    l = [tf.keras.layers.Conv2D(8,(3,3), padding='same', activation='relu',input_shape=(img_size, img_size,3)),]\n",
    "    for i in range(int(convs)):\n",
    "        if pooling=='avg':\n",
    "            l.append(tf.keras.layers.AvgPool2D())\n",
    "        if pooling=='max':\n",
    "            l.append(tf.keras.layers.MaxPool2D())\n",
    "        l.append(tf.keras.layers.Conv2D(2**(i+4),(3,3), padding='same', activation='relu'))\n",
    "    if flatten=='global':\n",
    "        l.append(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    else:\n",
    "        l.append(tf.keras.layers.Flatten())\n",
    "    l.append(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model = tf.keras.models.Sequential(l)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "params={'lr':0.001,\n",
    "        'pooling':'avg',\n",
    "        'flatten':'global',\n",
    "        'convs':5}\n",
    "\n",
    "model = getModel(**params)\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    convs = trial.suggest_int(\"convs\", 0, 3)\n",
    "    pooling = trial.suggest_categorical(\"pooling\", [\"no\",\"avg\", \"max\"])\n",
    "    flatten = trial.suggest_categorical(\"flatten\", [\"global\", \"flatten\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    model = getModel(lr, pooling, flatten, convs)\n",
    "    \n",
    "    history = model.fit(ds_train, # 10% of data\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0,\n",
    "                        validation_freq=1,\n",
    "                        validation_data=(ds_val),\n",
    "                        callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\")])\n",
    "    \n",
    "    return history.history['val_accuracy'][-1] # return last val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-30 21:38:41,789]\u001b[0m A new study created in memory with name: no-name-1f5e74dc-48e3-483b-bb76-08e0121e1f5e\u001b[0m\n",
      "<ipython-input-9-a46fcee01c42>:3: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  callbacks=[TensorBoardCallback('optuna-keras-logs2','val_accuracy')])\n",
      "\u001b[32m[I 2021-11-30 22:08:07,478]\u001b[0m Trial 0 finished with value: 0.019915254786610603 and parameters: {'convs': 0, 'pooling': 'no', 'flatten': 'global', 'lr': 0.05927084942607407}. Best is trial 0 with value: 0.019915254786610603.\u001b[0m\n",
      "\u001b[32m[I 2021-11-30 22:52:45,352]\u001b[0m Trial 1 finished with value: 0.03241525590419769 and parameters: {'convs': 0, 'pooling': 'no', 'flatten': 'flatten', 'lr': 0.012095518300665343}. Best is trial 1 with value: 0.03241525590419769.\u001b[0m\n",
      "\u001b[32m[I 2021-11-30 23:28:21,848]\u001b[0m Trial 2 finished with value: 0.2814618647098541 and parameters: {'convs': 0, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0011369511690982135}. Best is trial 2 with value: 0.2814618647098541.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 00:27:14,467]\u001b[0m Trial 3 finished with value: 0.3311440646648407 and parameters: {'convs': 1, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0002705086900617309}. Best is trial 3 with value: 0.3311440646648407.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 01:25:08,857]\u001b[0m Trial 4 finished with value: 0.019915254786610603 and parameters: {'convs': 1, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.059155192392171485}. Best is trial 3 with value: 0.3311440646648407.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 02:33:15,643]\u001b[0m Trial 5 finished with value: 0.14608050882816315 and parameters: {'convs': 1, 'pooling': 'max', 'flatten': 'flatten', 'lr': 0.00027886469205863206}. Best is trial 3 with value: 0.3311440646648407.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 02:39:24,097]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 03:40:02,201]\u001b[0m Trial 7 finished with value: 0.1878177970647812 and parameters: {'convs': 1, 'pooling': 'max', 'flatten': 'flatten', 'lr': 6.265319329172288e-05}. Best is trial 3 with value: 0.3311440646648407.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 07:01:40,414]\u001b[0m Trial 8 finished with value: 0.4764830470085144 and parameters: {'convs': 2, 'pooling': 'no', 'flatten': 'global', 'lr': 0.00652569720251998}. Best is trial 8 with value: 0.4764830470085144.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 07:03:16,592]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 07:26:34,055]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 08:35:08,460]\u001b[0m Trial 11 finished with value: 0.6713982820510864 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0013234805544161227}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 09:44:13,636]\u001b[0m Trial 12 finished with value: 0.6111229062080383 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0024885452823781044}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 10:53:08,794]\u001b[0m Trial 13 finished with value: 0.629025399684906 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0015107588400235894}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 11:59:15,609]\u001b[0m Trial 14 finished with value: 0.5546610355377197 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.00038429402966820054}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 12:59:46,554]\u001b[0m Trial 15 finished with value: 0.548305094242096 and parameters: {'convs': 2, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0017406929797431482}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 13:02:51,503]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 13:06:11,012]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 13:22:13,540]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 13:25:34,643]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 13:29:02,833]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 14:38:28,779]\u001b[0m Trial 21 finished with value: 0.6311440467834473 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0018157659589759414}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 15:47:44,280]\u001b[0m Trial 22 finished with value: 0.6369703412055969 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0006462371088533836}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 15:57:25,431]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 17:07:24,195]\u001b[0m Trial 24 finished with value: 0.630084753036499 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0032786837127515957}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 17:10:47,479]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 17:28:01,106]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 18:33:42,482]\u001b[0m Trial 27 finished with value: 0.6077330708503723 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0005416151814692229}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 18:36:44,151]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 19:34:34,983]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 20:04:52,769]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 21:09:58,113]\u001b[0m Trial 31 finished with value: 0.6692796349525452 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.002480465441520867}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 22:15:55,326]\u001b[0m Trial 32 finished with value: 0.6387711763381958 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.002355795198727428}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 22:19:13,939]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 22:22:32,301]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 23:28:35,975]\u001b[0m Trial 35 finished with value: 0.6086864471435547 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0008996796643557845}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 23:32:00,615]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 23:33:30,879]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 23:36:58,154]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 23:40:33,679]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-01 23:43:46,395]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 00:52:44,209]\u001b[0m Trial 41 finished with value: 0.6329449415206909 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0019296866188372155}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 01:44:00,328]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 14.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 01:47:23,904]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 02:11:02,814]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 02:14:24,595]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 02:17:25,506]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 03:24:28,903]\u001b[0m Trial 47 finished with value: 0.6697033643722534 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0021904971689551004}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 03:27:56,143]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 03:31:15,288]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 03:32:45,428]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 04:39:12,089]\u001b[0m Trial 51 finished with value: 0.6628177762031555 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0020005974641160505}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-02 05:05:42,481]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 7.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 05:09:01,319]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 06:15:43,616]\u001b[0m Trial 54 finished with value: 0.6260592937469482 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0029347507592634267}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 06:22:21,832]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 06:25:40,458]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 06:28:49,225]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 06:32:04,614]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 06:35:20,365]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 06:38:23,996]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 07:43:31,347]\u001b[0m Trial 61 finished with value: 0.6426906585693359 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0016557650763173051}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 08:48:41,387]\u001b[0m Trial 62 finished with value: 0.6537076234817505 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0014974906870220015}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 09:57:26,664]\u001b[0m Trial 63 finished with value: 0.6447033882141113 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0017040832215024272}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 10:04:20,063]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 10:07:46,105]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 10:41:51,409]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 11:20:00,827]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 10.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 11:22:47,409]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 11:53:45,901]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 11:57:14,581]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 12:00:43,116]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 12:27:54,834]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 7.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 12:31:17,913]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 12:34:37,388]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 12:50:52,367]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 4.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 12:57:25,822]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 13:00:47,367]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 14:05:32,490]\u001b[0m Trial 78 finished with value: 0.6325212121009827 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.001156945889121495}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 14:08:48,621]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 14:11:47,315]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 14:15:04,002]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 15:20:33,607]\u001b[0m Trial 82 finished with value: 0.6525423526763916 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0015587859065636276}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 15:23:51,562]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 15:30:19,544]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 16:34:43,643]\u001b[0m Trial 85 finished with value: 0.6709745526313782 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0027921673799563237}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 16:38:01,528]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 17:00:56,823]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 17:11:03,914]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 17:14:27,161]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 17:17:49,497]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 18:24:58,778]\u001b[0m Trial 91 finished with value: 0.6551907062530518 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0020396384183621755}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 19:32:01,470]\u001b[0m Trial 92 finished with value: 0.6605932116508484 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0019447596710891887}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 20:40:31,640]\u001b[0m Trial 93 finished with value: 0.6691737174987793 and parameters: {'convs': 3, 'pooling': 'avg', 'flatten': 'global', 'lr': 0.0020273400701534407}. Best is trial 11 with value: 0.6713982820510864.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 21:01:13,136]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 21:14:33,838]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 21:44:30,326]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 8.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 21:47:43,820]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 21:50:16,466]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-12-02 21:53:35,847]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  67\n",
      "  Number of complete trials:  33\n",
      "Best trial:\n",
      "  Value:  0.6713982820510864\n",
      "  Params: \n",
      "    convs: 3\n",
      "    pooling: avg\n",
      "    flatten: global\n",
      "    lr: 0.0013234805544161227\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # ==> maximize accuracy\n",
    "study.optimize(objective, n_trials=100, timeout=None,\n",
    "               callbacks=[TensorBoardCallback('optuna-keras-logs2','val_accuracy')])\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c0c2f682fab64cb3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c0c2f682fab64cb3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6015;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir optuna-keras-logs2 --port 6015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary / extra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
